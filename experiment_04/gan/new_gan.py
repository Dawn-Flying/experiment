"åˆ†æ‰¹è¯»å–CIFAR-10å›¾ç‰‡å¹¶å°†éƒ¨åˆ†æ‰¹æ¬¡ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶"
import os

import torch
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torchvision.utils import save_image

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

dataset = CIFAR10(root='./data', download=True,
                  transform=transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)  # å–‚å…¥å¤§å°æ˜¯æŠŠåŸæ¥æ•°æ®é›†ä¸­çš„å¤šå°‘å›¾ç‰‡ç»„åˆæˆä¸€å¼ å›¾ç‰‡
batch_size = 64
for batch_idx, data in enumerate(dataloader):
    if batch_idx == len(dataloader) - 1:
        continue
    real_images, _ = data

    print('#{} has {} images.'.format(batch_idx, batch_size))
    if batch_idx % 100 == 0:
        path = './data/CIFAR10_shuffled_batch{:03d}.png'.format(batch_idx)
        save_image(real_images, path, normalize=True)

"æ­å»ºç”Ÿæˆç½‘ç»œå’Œé‰´åˆ«ç½‘ç»œ"
"éšè—çš„å·ç§¯å±‚(å³é™¤äº†æœ€åçš„è¾“å‡ºå·ç§¯å±‚å¤–)çš„è¾“å‡ºéƒ½éœ€è¦ç»è¿‡è§„èŒƒåŒ–æ“ä½œ"
import torch.nn as nn

# æ­å»ºç”Ÿæˆç½‘ç»œ
latent_size = 64  # æ½œåœ¨å¤§å°
n_channel = 3  # è¾“å‡ºé€šé“æ•°
n_g_feature = 64  # ç”Ÿæˆç½‘ç»œéšè—å±‚å¤§å°
"ç”Ÿæˆç½‘ç»œé‡‡ç”¨äº†å››å±‚è½¬ç½®å·ç§¯æ“ä½œ"
gnet = nn.Sequential(
    # è¾“å…¥å¤§å° = (64, 1, 1)
    # æœ‰ç‚¹åƒäº’ç›¸å…³çš„åæ“ä½œï¼Œ(x-4)/1=1-->x=4
    nn.ConvTranspose2d(latent_size, 4 * n_g_feature, kernel_size=4,
                       bias=False),
    nn.BatchNorm2d(4 * n_g_feature),
    nn.ReLU(),
    # å¤§å° = (256, 4, 4)
    # {x+2(å¡«å……)-4(æ ¸å°ºå¯¸)+2(æ­¥é•¿)}/2=4-->x=8
    nn.ConvTranspose2d(4 * n_g_feature, 2 * n_g_feature, kernel_size=4,
                       stride=2, padding=1, bias=False),
    nn.BatchNorm2d(2 * n_g_feature),
    nn.ReLU(),
    # å¤§å° = (128, 8, 8)
    nn.ConvTranspose2d(2 * n_g_feature, n_g_feature, kernel_size=4,
                       stride=2, padding=1, bias=False),
    nn.BatchNorm2d(n_g_feature),
    nn.ReLU(),
    # å¤§å° = (64, 16, 16)
    nn.ConvTranspose2d(n_g_feature, n_channel, kernel_size=4,
                       stride=2, padding=1),
    nn.Sigmoid(),
    # å›¾ç‰‡å¤§å° = (3, 32, 32)
)
print(gnet)

# æ­å»ºé‰´åˆ«ç½‘ç»œ
n_d_feature = 64  # é‰´åˆ«ç½‘ç»œéšè—å±‚å¤§å°
"é‰´åˆ«ç½‘ç»œé‡‡ç”¨äº†4å±‚äº’ç›¸å…³æ“ä½œ"
dnet = nn.Sequential(
    # å›¾ç‰‡å¤§å° = (3, 32, 32)
    nn.Conv2d(n_channel, n_d_feature, kernel_size=4,
              stride=2, padding=1),
    nn.LeakyReLU(0.2),
    # å¤§å° = (64, 16, 16)
    nn.Conv2d(n_d_feature, 2 * n_d_feature, kernel_size=4,
              stride=2, padding=1, bias=False),
    nn.BatchNorm2d(2 * n_d_feature),
    nn.LeakyReLU(0.2),
    # å¤§å° = (128, 8, 8)
    nn.Conv2d(2 * n_d_feature, 4 * n_d_feature, kernel_size=4,
              stride=2, padding=1, bias=False),
    nn.BatchNorm2d(4 * n_d_feature),
    nn.LeakyReLU(0.2),
    # å¤§å° = (256, 4, 4)
    nn.Conv2d(4 * n_d_feature, 1, kernel_size=4),
    # å¯¹æ•°èµ”ç‡å¼ é‡å¤§å° = (1, 1, 1)
)
print(dnet)

gnet = gnet.to(device)
dnet = dnet.to(device)

"åˆå§‹åŒ–æƒé‡å€¼"
import torch.nn.init as init
import matplotlib.pyplot as plt

def weights_init(m):  # ç”¨äºåˆå§‹åŒ–æƒé‡å€¼çš„å‡½æ•°
    if type(m) in [nn.ConvTranspose2d, nn.Conv2d]:
        init.xavier_normal_(m.weight)
    elif type(m) == nn.BatchNorm2d:
        init.normal_(m.weight, 1.0, 0.02)
        init.constant_(m.bias, 0)


# è°ƒç”¨apply()å‡½æ•°ï¼Œtorch.nn.Moduleç±»å®ä¾‹ä¼šé€’å½’åœ°è®©è‡ªå·±æˆä¸ºweights_init()é‡Œé¢å‡½æ•°çš„m
gnet.apply(weights_init)
dnet.apply(weights_init)



if __name__ == '__main__':
    "è®­ç»ƒç”Ÿæˆç½‘ç»œå’Œé‰´åˆ«ç½‘ç»œå¹¶è¾“å‡ºå›¾ç‰‡"
    import torch
    import torch.optim

    # æŸå¤±
    criterion = nn.BCEWithLogitsLoss()

    # ä¼˜åŒ–å™¨
    #Adamä¼˜åŒ–å™¨çš„é»˜è®¤å­¦ä¹ ç‡n=0.01,è¿‡é«˜ï¼Œåº”å‡å°ä¸º0.002ï¼ŒåŠ¨é‡å‚æ•°é»˜è®¤0.9ï¼Œä¼šé€ æˆéœ‡è¡ï¼Œå‡å°ä¸º0.5
    goptimizer = torch.optim.Adam(gnet.parameters(),
        lr=0.0002, betas=(0.5, 0.999))
    doptimizer = torch.optim.Adam(dnet.parameters(),
        lr=0.0002, betas=(0.5, 0.999))

    # ç”¨äºæµ‹è¯•çš„å›ºå®šå™ªå£°,ç”¨æ¥æŸ¥çœ‹ç›¸åŒçš„æ½œåœ¨å¼ é‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆå›¾ç‰‡çš„å˜æ¢
    batch_size = 64
    fixed_noises = torch.randn(batch_size, latent_size, 1, 1, device=device)

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs('./generated_images', exist_ok=True)
    os.makedirs('./real_images_for_fid', exist_ok=True)

    # === å…ˆä¿å­˜æ‰€æœ‰çœŸå®å›¾åƒï¼ˆç”¨äº FIDï¼‰===
    print("Saving real CIFAR-10 images for FID...")
    real_img_count = 0
    for batch_idx, (real_imgs, _) in enumerate(
            DataLoader(CIFAR10(root='./data', train=True, transform=transforms.ToTensor()), batch_size=64)):
        for i in range(real_imgs.size(0)):
            save_image(real_imgs[i], f'./real_images_for_fid/real_{real_img_count:05d}.png')
            real_img_count += 1
        if real_img_count >= 50000:
            break
    print(f"Saved {real_img_count} real images to ./real_images_for_fid")

    # è®­ç»ƒè¿‡ç¨‹
    # === è®­ç»ƒè®°å½• ===
    G_losses = []
    D_losses = []

    epoch_num = 10
    for epoch in range(epoch_num):
        g_loss_epoch = 0.0
        d_loss_epoch = 0.0
        num_batches = 0

        for batch_idx, data in enumerate(dataloader):
            if batch_idx==len(dataloader)-1: #å‰”é™¤æœ€åä¸€å¼ æ˜¯(16,3,32,32)
                continue
            # è½½å…¥æœ¬æ‰¹æ¬¡æ•°æ®
            real_images, _ = data#real_images(64,3,32,32)
            real_images = real_images.to(device)  # ğŸ‘ˆ å…³é”®ï¼šæ•°æ®ä¸Š GPU

            # è®­ç»ƒé‰´åˆ«ç½‘ç»œ
            labels = torch.ones(batch_size, device=device) # çœŸå®æ•°æ®å¯¹åº”æ ‡ç­¾ä¸º1(64,)
            preds = dnet(real_images) # å¯¹çœŸå®æ•°æ®è¿›è¡Œåˆ¤åˆ«(64,1,1,1)

            outputs = preds.reshape(-1)#(64,)
            dloss_real = criterion(outputs, labels) # çœŸå®æ•°æ®çš„é‰´åˆ«å™¨æŸå¤±
            dmean_real = outputs.sigmoid().mean() # è®¡ç®—é‰´åˆ«å™¨å°†å¤šå°‘æ¯”ä¾‹çš„çœŸæ•°æ®åˆ¤å®šä¸ºçœŸ,ä»…ç”¨äºè¾“å‡ºæ˜¾ç¤º

            noises = torch.randn(batch_size, latent_size, 1, 1, device=device) # æ½œåœ¨å™ªå£°(64,64,1,1)
            fake_images = gnet(noises) # ç”Ÿæˆå‡æ•°æ®(64,3,32,32)
            labels = torch.zeros(batch_size, device=device) # å‡æ•°æ®å¯¹åº”æ ‡ç­¾ä¸º0
            fake = fake_images.detach()# ä½¿å¾—æ¢¯åº¦çš„è®¡ç®—ä¸å›æº¯åˆ°ç”Ÿæˆç½‘ç»œ,å¯ç”¨äºåŠ å¿«è®­ç»ƒé€Ÿåº¦.åˆ å»æ­¤æ­¥ç»“æœä¸å˜
            preds = dnet(fake) # å¯¹å‡æ•°æ®è¿›è¡Œé‰´åˆ«
            outputs = preds.view(-1)

            dloss_fake = criterion(outputs, labels) # å‡æ•°æ®çš„é‰´åˆ«å™¨æŸå¤±
            dmean_fake = outputs.sigmoid().mean()
                    # è®¡ç®—é‰´åˆ«å™¨å°†å¤šå°‘æ¯”ä¾‹çš„å‡æ•°æ®åˆ¤å®šä¸ºçœŸ,ä»…ç”¨äºè¾“å‡ºæ˜¾ç¤º

            dloss = dloss_real + dloss_fake # æ€»çš„é‰´åˆ«å™¨æŸå¤±
            dnet.zero_grad()
            dloss.backward()
            doptimizer.step()

            # è®­ç»ƒç”Ÿæˆç½‘ç»œ
            labels = torch.ones(batch_size, device=device)
                    # ç”Ÿæˆç½‘ç»œå¸Œæœ›æ‰€æœ‰ç”Ÿæˆçš„æ•°æ®éƒ½è¢«è®¤ä¸ºæ˜¯çœŸæ•°æ®
            preds = dnet(fake_images) # æŠŠå‡æ•°æ®é€šè¿‡é‰´åˆ«ç½‘ç»œ
            outputs = preds.view(-1)
            gloss = criterion(outputs, labels) # çœŸæ•°æ®çœ‹åˆ°çš„æŸå¤±
            gmean_fake = outputs.sigmoid().mean()
                    # è®¡ç®—é‰´åˆ«å™¨å°†å¤šå°‘æ¯”ä¾‹çš„å‡æ•°æ®åˆ¤å®šä¸ºçœŸ,ä»…ç”¨äºè¾“å‡ºæ˜¾ç¤º
            gnet.zero_grad()
            gloss.backward()
            goptimizer.step()

            # --- Accumulate losses ---
            g_loss_epoch += gloss.item()
            d_loss_epoch += dloss.item()
            num_batches += 1

            # è¾“å‡ºæœ¬æ­¥è®­ç»ƒç»“æœ
            if batch_idx % 100 == 0:
                print('[{}/{}]'.format(epoch, epoch_num) +
                        '[{}/{}]'.format(batch_idx, len(dataloader)) +
                        'é‰´åˆ«ç½‘ç»œæŸå¤±:{:g} ç”Ÿæˆç½‘ç»œæŸå¤±:{:g}'.format(dloss, gloss) +
                        'çœŸæ•°æ®åˆ¤çœŸæ¯”ä¾‹:{:g} å‡æ•°æ®åˆ¤çœŸæ¯”ä¾‹:{:g}/{:g}'.format(
                        dmean_real, dmean_fake, gmean_fake))
                fake = gnet(fixed_noises) # ç”±å›ºå®šæ½œåœ¨å¼ é‡ç”Ÿæˆå‡æ•°æ®
                save_image(fake, # ä¿å­˜å‡æ•°æ®
                        './data/images_epoch{:02d}_batch{:03d}.png'.format(
                        epoch, batch_idx))

        # --- Epoch ç»“æŸ ---
        avg_g = g_loss_epoch / num_batches
        avg_d = d_loss_epoch / num_batches
        G_losses.append(avg_g)
        D_losses.append(avg_d)

        print(f"[Epoch {epoch}/{epoch_num}] G_loss: {avg_g:.4f}, D_loss: {avg_d:.4f}")

        # === ä¿å­˜ 50,000 å¼ ç”Ÿæˆå›¾åƒç”¨äº FID ===
        print("Generating 50,000 fake images for FID...")
        gen_img_count = 0
        with torch.no_grad():
            while gen_img_count < 50000:
                noise = torch.randn(batch_size, latent_size, 1, 1, device=device)
                fake_imgs = gnet(noise)
                for i in range(fake_imgs.size(0)):
                    if gen_img_count >= 50000:
                        break
                    save_image(fake_imgs[i].cpu(), f'./generated_images/fake_{gen_img_count:05d}.png', normalize=True)
                    gen_img_count += 1
        print(f"Saved {gen_img_count} generated images to ./generated_images")

        # === ç»˜åˆ¶æŸå¤±æ›²çº¿ ===
        plt.figure(figsize=(10, 5))
        plt.plot(G_losses, label='Generator Loss')
        plt.plot(D_losses, label='Discriminator Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('DCGAN Training Loss (BCEWithLogitsLoss)')
        plt.legend()
        plt.grid(True)
        plt.savefig('./data/gan_loss_curve.png')
        plt.show()


        # === è°ƒç”¨ FID/IS è¯„ä¼° ===
        def fidelity_metric(generated_images_path, real_images_path):
            try:
                import torch_fidelity
            except ImportError:
                print("âš ï¸ torch-fidelity not installed. Skipping FID/IS calculation.")
                print("Install it via: pip install torch-fidelity")
                return {"fid": "N/A", "isc": "N/A"}

            metrics_dict = torch_fidelity.calculate_metrics(
                input1=generated_images_path,
                input2=real_images_path,
                cuda=torch.cuda.is_available(),
                isc=True,
                fid=True,
                kid=False,
                verbose=False,
                samples_find_deep=True
            )
            return metrics_dict


        print("Computing FID and IS...")
        results = fidelity_metric('./generated_images', './real_images_for_fid')
        print("Evaluation Results:")
        print(f"  FID: {results.get('frechet_inception_distance', 'N/A')}")
        print(f"  IS (mean): {results.get('inception_score_mean', 'N/A')}")
        print(f"  IS (std): {results.get('inception_score_std', 'N/A')}")

