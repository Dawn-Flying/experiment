# 实验二 医学图像检测实验报告

仓库地址：https://github.com/Dawn-Flying/experiment

## 1.实验目的

​		根据彩色眼底图像判断是否出现疾病。

## 2.数据集介绍

- 训练数据集：以jpg格式存储在2-MedImage-TrainSet中。
- 测试数据集：以jpg格式存储在2-MedImage-TestSet。

每个数据集目录下，共两个文件夹disease和normal，标签即文件夹名称。

训练集包含646张disease图像与993张normal图像。测试集由150张normal与100张disease组成。

## 3.实验步骤

### 3.1 获取数据集

最终数据集存放目录：

- 数据根目录 data 
- 训练集目录 data/2-MedImage-TrainSet
- 测试集目录 data/2-MedImage-TestSet

<img src="C:\Users\Angel\AppData\Roaming\Typora\typora-user-images\image-20251209232723288.png" alt="image-20251209232723288" style="zoom:50%;" />

### 3.2 自定义数据集

```python
class FundusDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = []
        self.labels = []

        # 遍历 disease 和 normal 文件夹
        for label, folder in enumerate(['disease', 'normal']):
            folder_path = os.path.join(root_dir, folder)
            if not os.path.exists(folder_path):
                continue
            for img_name in os.listdir(folder_path):
                self.images.append(os.path.join(folder_path, img_name))
                self.labels.append(label)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert("RGB")
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label
    
# =================== 数据增强 ===================
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.1, contrast=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}

# =================== 加载数据 ===================
train_dataset = FundusDataset(root_dir="./data/2-MedImage-TrainSet", transform=data_transforms['val'])
val_dataset = FundusDataset(root_dir="./data/2-MedImage-TestSet", transform=data_transforms['val'])

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
```



### 3.3 训练ResNet50模型

​		ResNet中文意思是残差神经网络。在2015年的ImageNet比赛中，模型的分类能力首次超越人眼，1000类图片top-5的错误率降低到3.57%。在原论文中作者给出了18层、34层、50层、101层与152层的ResNet。101层的与152层的残差神经网络效果最好，但是受硬件设备以及推断时间的限制，50层的残差神经网络在实际项目中更为常用。

#### 3.3.1 网络退化问题

虽说研究已经证明，随着网络深度的不断增加，网络的整体性能也会提升。如果只是单纯的增加网络，就会引起以下两个问题：第一，模型容易过拟合；第二，产生梯度消失、梯度爆炸的问题。

虽然随着研究的不断发展，以上两个问题都可以被解决掉，但是ResNet网络的作者发现，以上两个问题被规避之后，简单的堆叠卷积层，依然不能获得很好的效果。

为了验证刚才的观点，作者做了这样的一个实验。通过搭建一个普通的20层卷积神经网络与一个56层的卷积神经网络，在CIFAR-10数据集上进行了验证。无论训练集误差还是测试集误差，56层的网络均高于20层的网络。下图来源于论文。

<img src="file:///D:/Study/阅读/极客/001-PyTorch深度学习实战/images/446645/8503d95991270ea2d4a3ff80622af375.png" alt="img" style="zoom:50%;" />

出现这样的情况，作者认为这是网络退化造成的。

网络退化是指当一个网络可以开始收敛时，随着网络层数的增加，网络的精度逐渐达到饱和，并且会迅速降低。这里精度降低的原因并不是过拟合造成的，因为如果是过拟合，上图中56层的在训练集上的精度应该高于20层的精度。

作者认为这一现象并不合理，假设20层是一个最优的网络，通过加深到56层之后，理论上后面的36层是可以通过学习到一个恒等映射的，也就是说理论上不会学习到一个比26层还差的网络。所以，作者猜测网络不能很容易地学习到恒等映射(恒等映射就是f(x)=x)。

#### 3.3.2 残差学习

正如刚才所说，从网络退化问题中可以发现，通过简单堆叠卷积层似乎很难学会到恒等映射。为了改善网络退化问题，论文作者何凯明提出了一种深度残差学习的框架。

因为网络不容易学习到恒等映射，所以就让它强制添加一个恒等映射，如下图所示（下图来源于论文）。

![img](file:///D:/Study/阅读/极客/001-PyTorch深度学习实战/images/446645/27c8c4a22782ab29e77c36d0131f5e3b.png)

具体实现是通过一种叫做shortcut connection的机制来完成的。在残差神经网络中shortcut connection就是恒等变换，就是上图中带有x identity的那条曲线，包含shortcut connection的几层网络我们称之为残差块。

残差块被定义为：$$y = F(x, W_i) + x$$

F可以是2层的卷积层。也可以是3层的卷积层。最后作者发现，通过残差块，就可以训练出更深、更加优秀的卷积神经网络了。

网络模型如下图所示：

![image-20251209234919615](C:\Users\Angel\AppData\Roaming\Typora\typora-user-images\image-20251209234919615.png)



#### 3.3.2 模型训练

本次实验选用ResNet50模型，需修改最后的分类器，设置全连接层输出为1即可。

共训练10轮，学习率为0.001，损失函数使用二分类交叉熵损失函数。

``` 
# =================== 模型构建 ===================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet50(pretrained=True)
num_features = model.fc.in_features
model.fc = torch.nn.Linear(num_features, 1)  # 二分类输出
model.to(device)

# =================== 训练循环 ===================
criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 10

train_losses = []
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.float().to(device)
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_losses.append(running_loss / len(train_loader))
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}')

torch.save(model.state_dict(), './model.pth')

```



### 3.4 绘制图像损失函数

```python
plt.plot(train_losses, label='Training Loss')
plt.title('Loss per Epoch')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
```

损失变化如下图所示：

<img src="C:\Users\Angel\AppData\Roaming\Typora\typora-user-images\image-20251210004031695.png" alt="image-20251210004031695" style="zoom:67%;" />



## 4.实验结果分析

使用测试集验证模型性能，并绘制ROC曲线。

```python
# =================== 验证并预测 ===================
model.eval()
y_true = []
y_scores = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.float().to(device)
        outputs = model(inputs).squeeze()
        y_true.extend(labels.cpu().numpy())
        y_scores.extend(torch.sigmoid(outputs).cpu().numpy())

# ===================  绘制 ROC 曲线 ===================
fpr, tpr, _ = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

print(f"ROC AUC Score: {roc_auc:.4f}")

from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score

y_pred = [1 if score >= 0.5 else 0 for score in y_scores]

conf_matrix = confusion_matrix(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
acc = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)

print("Confusion Matrix: \n", conf_matrix)
print("F1 Score: ", f1)
print("Accuracy: ", acc)
print("Precision: ", precision)
print("Recall: ", recall)

# ====== 绘制混淆矩阵图 ======
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # 调整字体大小

# 创建热力图
sns.heatmap(
    conf_matrix,
    annot=True,  # 显示数字
    fmt='d',  # 整数格式
    cmap='Blues',  # 颜色主题
    xticklabels=[str(i) for i in range(2)],
    yticklabels=[str(i) for i in range(2)]
)

plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

```

ROC曲线如下图所示，AUC结果为0.93。

<img src="C:\Users\Angel\AppData\Roaming\Typora\typora-user-images\image-20251210004042030.png" alt="image-20251210004042030" style="zoom:67%;" />

测试集准确率为。混淆矩阵如下图所示。

<img src="C:\Users\Angel\AppData\Roaming\Typora\typora-user-images\image-20251210004056892.png" alt="image-20251210004056892" style="zoom:67%;" />

根据混淆矩阵，计算得到

F1 Score:  0.74
Accuracy:  0.74
Precision:  0.94
Recall:  0.61

此结果经过多次训练验证，因ResNet初始参数虽基于ImageNet预训练，但分类头（fc层）为随机初始化，且数据集规模有限、类别可能存在不平衡，导致每次训练在收敛细节上略有差异。尽管如此，AUC稳定在0.93左右，说明模型具备良好的判别能力；而召回率偏低的问题在多轮实验中持续存在，反映出当前训练策略或阈值设定对“疾病”类别的敏感性不足。

## 4.总结

​		本实验基于ResNet50模型对医学图像进行分类，在测试集上达到的准确率为61%，精确率Precision为95%。模型在眼底图像二分类任务中取得了较高的 AUC（0.93），表明其整体判别能力较强。然而，尽管精确率高达 0.94，召回率仅为0.61，说明模型倾向于保守预测。准确率和F1均为0.74，受类别分布影响较大，不宜作为主要评估依据。





